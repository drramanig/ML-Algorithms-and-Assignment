{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine  Non-Linear method (Radial Bais Function-rbf)\n",
    "\n",
    "# r_score=-0.05748629037548025\n",
    "\n",
    "# 1.Non-Linear data  2. Clusters  3. hyperplane 4.Vector/datapoints  \n",
    "\n",
    "# Standardization is used here to improve the result \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(\"50_Startups.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.get_dummies(dataset,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "independent=dataset[['R&D Spend', 'Administration', 'Marketing Spend', \n",
    "       'State_Florida', 'State_New York']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependent=dataset[['Profit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING AND TEST SET SPLIT UP\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, Y_train, Y_test= train_test_split(independent,dependent,test_size=0.30,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardisation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Phase\n",
    "## procedure- SVM is used for non-linear algorithm,\n",
    "# By implementing all the kernel options and comparing with the result to finalize the best model \n",
    "\n",
    "# kernel=rbf\n",
    "\n",
    "# from sklearn.svm import SVR \n",
    "# regressor=SVR(kernel=\"rbf\")\n",
    "# regressor.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By trying other kernel to check any changes in result, here poly is applied in kernel \n",
    "#kernel=poly\n",
    " \n",
    "#from sklearn.svm import SVR \n",
    "#regressor.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel=sigmoid \n",
    "\n",
    "#from sklearn.svm import SVR \n",
    "#regressor=SVR(kernel=\"sigmoid\")\n",
    "#regressor.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# kernel= precomputed.\n",
    "# This kernel needs square matrix ie., both the columns and rows should be equal, in this dataset it is not equal so this kernel wont workout. \n",
    "\n",
    "from sklearn.svm import SVR \n",
    "regressor=SVR(kernel=\"precomputed\")\n",
    "regressor.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel=rbf , with c=10,100,1000, C means correction for taking datapoints for clustering\n",
    "\n",
    "#from sklearn.svm import SVR \n",
    "#regressor=SVR(kernel=\"rbf\",C=10)\n",
    "#regressor.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to find the origin\n",
    "\n",
    "regressor.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to find number of datapoints taken for segregating the cluster\n",
    "\n",
    "regressor.n_support_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listing the daatpoints here 34 datapoints or vectors are used for cluster\n",
    "regressor.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred=regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluaation\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r_score=r2_score(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_score value should be near to 1 to confirm the best model.\n",
    "\n",
    "# But this algorithm results \n",
    "\n",
    "# for rbf(r_score)-0.0574 which is negative value for kernel rbf, \n",
    "# for poly(r_score=-0.05710387514922144),\n",
    "# for sigmoid(r_score=-0.05710387514922144)\n",
    "# for precomputed(r_score= maatrix value is not same)\n",
    "# for rbf, C=10 (r_score=-0.05680759285862336) \n",
    "# for rbf, C=100 (r_score=-0.05072602278128757)\n",
    "# for rbf, C=1000 (r_score=0.0067683444800727965)\n",
    "\n",
    "# After analysing the results the r_score value is not improved for all optinal kernels and c values. \n",
    "\n",
    "# so it is concluded this algorithm is not performing good for the given dataset,it may work for other dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
